# Problems: flash_attention causes issues with timm which is required by the model
# dora and rslora together cause issues with cut cross entropy plugin
# Most important part: tune lora_r, lora_alpha, learning rate, and num_epochs

base_model: mistralai/Mistral-Nemo-Instruct-2407
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer

# Quantization & LoRA

load_in_4bit: true
adapter: qlora
# Experiemnt with rslora first
peft_use_dora: false
peft_use_rslora: true
lora_r: 32
lora_alpha: 64 # Consider using 16 to prevent overwriting pre-trained weights
lora_dropout: 0.05
lora_target_linear: true

# Hardware & Speed

flash_attention: true
xformers_attention: false
bf16: true
fp16: false
plugins:
  - axolotl.integrations.cut_cross_entropy.CutCrossEntropyPlugin

# Context & Batching

sample_packing: true
eval_sample_packing: true
pad_to_sequence_len: true
sequence_len: 12000

# Gradient accumulation = 16 * 1 micro_batch * 3 GPUs = Global Batch 48
# Or 8 * 2 micro_batch * 3 GPUs = Global Batch 48

micro_batch_size: 2
gradient_accumulation_steps: 8
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

# Optimizer & Training

learning_rate: 0.0001
optimizer: paged_adamw_8bit
lr_scheduler: cosine
warmup_ratio: 0.1
eval_steps: 10
save_steps: 10
num_epochs: 2
logging_steps: 1
early_stopping_patience: 4
# load_best_model_at_end: true
output_dir: ./outputs/bananabernini_12b

# Dataset Configuration
chat_template: tokenizer_default
shuffle_merged_datasets: true
datasets:
  - path: training_data.jsonl
    type: chat_template
    chat_template: tokenizer_default
    field_messages: messages
    message_property_mappings:
      role: from
      content: value

test_datasets:
  - path: test_data.jsonl
    type: chat_template
    chat_template: tokenizer_default
    field_messages: messages
    message_property_mappings:
      role: from
      content: value

# Data Loading

dataloader_prefetch_factor: 4
dataloader_num_workers: 4
dataloader_pin_memory: true

# Multi-GPU settings

deepspeed: deepspeed_configs/zero2.json

# Regularization
# neftune_noise_alpha: 5

trust_remote_code: true

strict: false
